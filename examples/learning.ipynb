{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Learning Algorithms in Gridworld</h2>\n",
    "\n",
    "- ### Q-learning with synchronous sampling\n",
    "\n",
    "    > Synchronous sampling samples a state transition for each (s, a) pair. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrd\n",
    "import jax\n",
    "import jaxdp\n",
    "\n",
    "from jaxdp.learning.algorithms import q_learning\n",
    "from jaxdp.learning.runner import train\n",
    "\n",
    "\n",
    "# Define the arguments\n",
    "args = dict(\n",
    "    seed=42,\n",
    "    n_seeds=10,\n",
    "    update_fn=dict(\n",
    "        alpha=0.1\n",
    "    ),\n",
    "    train_loop=dict(\n",
    "        gamma=0.99,\n",
    "        n_steps=100,\n",
    "        eval_period=10,\n",
    "    ),\n",
    "    value_init=dict(\n",
    "        minval=0.0,\n",
    "        maxval=1.0\n",
    "    ),\n",
    "    mdp_init=dict(\n",
    "        p_slip=0.15,\n",
    "        board=[\"#####\",\n",
    "               \"#  @#\",\n",
    "               \"#  X#\",\n",
    "               \"#P  #\",\n",
    "               \"#####\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Initiate the MDP and the Q values\n",
    "_train_key, value_key = jrd.split(jrd.PRNGKey(args[\"seed\"]), 2)\n",
    "train_keys = jrd.split(_train_key, args[\"n_seeds\"])\n",
    "mdp = jaxdp.mdp.grid_world(**args[\"mdp_init\"])\n",
    "init_value = jrd.uniform(value_key, (mdp.action_size, mdp.state_size,),\n",
    "                         dtype=\"float32\", **args[\"value_init\"])\n",
    "\n",
    "# Define learner function\n",
    "def update_fn(index, sample, value, learner_state, gamma):\n",
    "    next_value = q_learning.synchronous.step(sample, value, gamma)\n",
    "    return q_learning.update(value, next_value, alpha=args[\"update_fn\"][\"alpha\"]), None\n",
    "\n",
    "\n",
    "# Train a policy for 10 different seeds (After JIT compiling the \"batch\" train function)\n",
    "jitted_batch_train = jax.jit(\n",
    "    jax.vmap(\n",
    "        partial(\n",
    "            train.synchronous,\n",
    "            learner_state=None,\n",
    "            value_star=jnp.full_like(init_value, jnp.nan),\n",
    "            target_policy_fn=lambda q, i: jaxdp.greedy_policy.q(q),\n",
    "            update_fn=update_fn,\n",
    "            **args[\"train_loop\"]\n",
    "        ), in_axes=(None, None, 0))\n",
    ")\n",
    "metrics, value, learner_state = jitted_batch_train(\n",
    "    init_value,\n",
    "    mdp,\n",
    "    train_keys\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from plot_util import make_figure\n",
    "\n",
    "\n",
    "# Make dataframe from the metrics\n",
    "percentile = 25\n",
    "\n",
    "index = pd.MultiIndex.from_product(\n",
    "    [[\"gridworld\"], [\"q-learning\"], list(range(args[\"train_loop\"][\"n_steps\"]))],\n",
    "    names=[\"ENV\", \"ALG\", \"STEP\"])\n",
    "columns = pd.MultiIndex.from_product(\n",
    "    [metrics._fields, [\"low\", \"med\", \"high\"]],\n",
    "    names=[\"METRIC\", \"PERCENTILE\"])\n",
    "\n",
    "data = []\n",
    "for name in metrics._fields:\n",
    "    values = getattr(metrics, name)\n",
    "    if values.ndim == 1:\n",
    "        values = values.reshape(1, -1)\n",
    "    percentiles = jnp.nanpercentile(\n",
    "        values, q=jnp.array([percentile, 50, 100 - percentile]), axis=0)\n",
    "    data.append(percentiles)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=jnp.stack(list(chain(*data)), axis=1), columns=columns, index=index)\n",
    "\n",
    "# Generate the figure\n",
    "make_figure(df.loc[\"gridworld\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Q-learning with asynchronous sampling\n",
    "\n",
    "    > Asynchronous sampling samples a state transition by following a behavior policy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial, reduce\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrd\n",
    "import jax\n",
    "import jaxdp\n",
    "\n",
    "from jaxdp.learning.algorithms import q_learning\n",
    "from jaxdp.learning.runner import train, reducer\n",
    "from jaxdp.learning.sampler import SamplerState, rollout_sample\n",
    "\n",
    "# Define the arguments\n",
    "args = dict(\n",
    "    seed=42,                   # Initial seeds\n",
    "    n_seeds=10,                # Number of seeds to execute the same algorithm\n",
    "    n_env=4,                   # Number of parallel environments for sampling\n",
    "    policy_fn=dict(\n",
    "        epsilon=0.15           # Epsilon-greedy parameter\n",
    "    ),\n",
    "    update_fn=dict(\n",
    "        alpha=0.10             # Step size (a.k.a learning rate)\n",
    "    ),\n",
    "    train_loop=dict(\n",
    "        gamma=0.99,            # Discount factor\n",
    "        n_steps=1000,          # Number of steps\n",
    "        eval_period=50,        # Evaluation period (in terms of <n_steps>)\n",
    "    ),\n",
    "    sampler_init=dict(\n",
    "        queue_size=50,         # Queue size of the sampler for the metrics\n",
    "    ),\n",
    "    sampler_fn=dict(\n",
    "        max_episode_length=15,  # Maximum length of an episode allowed by the sampler\n",
    "        rollout_len=10,        # Length of a rollout\n",
    "    ),\n",
    "    value_init=dict(\n",
    "        minval=0.0,            # Minimum value of the uniform distribution\n",
    "        maxval=1.0             # Maxiumum value of the uniform distribution\n",
    "    ),\n",
    "    mdp_init=dict(\n",
    "        p_slip=0.15,           # Probability of slipping\n",
    "        board=[\"#####\",        # The board of the gridworld\n",
    "               \"#  @#\",\n",
    "               \"#  X#\",\n",
    "               \"#P  #\",\n",
    "               \"#####\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Initiate the MDP and the Q values\n",
    "train_key, sampler_key, value_key = jrd.split(jrd.PRNGKey(args[\"seed\"]), 3)\n",
    "train_keys = jrd.split(train_key, args[\"n_seeds\"])\n",
    "mdp = jaxdp.mdp.grid_world(**args[\"mdp_init\"])\n",
    "init_value = jrd.uniform(value_key, (mdp.action_size, mdp.state_size,),\n",
    "                         dtype=\"float32\", **args[\"value_init\"])\n",
    "\n",
    "# Define learner function\n",
    "# For multiple sampling environments\n",
    "batch_step_fn = jax.vmap(jax.vmap(q_learning.asynchronous.step, (0, None, None)), (0, None, None))\n",
    "\n",
    "\n",
    "def batch_update_fn(index, rollouts, value, learner_state, gamma):\n",
    "    scalar_target_values = batch_step_fn(rollouts, value, gamma)\n",
    "    target_value = reducer.every_visit(rollouts, scalar_target_values)\n",
    "    return q_learning.update(\n",
    "        value, target_value, alpha=args[\"update_fn\"][\"alpha\"]\n",
    "    ), None\n",
    "\n",
    "\n",
    "# Initiate sampler\n",
    "# For single sampling environment\n",
    "sampler_state = SamplerState.initialize_rollout_state(\n",
    "    mdp,\n",
    "    **args[\"sampler_init\"],\n",
    "    init_state_key=sampler_key)\n",
    "# For multiple sampling environments\n",
    "n_env_sampler_state = jax.vmap(SamplerState.initialize_rollout_state, (None, None, 0)\n",
    "                               )(mdp,\n",
    "                                 args[\"sampler_init\"][\"queue_size\"],\n",
    "                                 jrd.split(sampler_key, args[\"n_env\"])\n",
    "                                 )\n",
    "n_env_sampler = jax.vmap(partial(rollout_sample, **args[\"sampler_fn\"]), (0, None, 0, None))\n",
    "\n",
    "\n",
    "# Train a policy for 10 different seeds (After JIT compiling the \"batch\" train function)\n",
    "# In each step, collect a rollout from <n_env> many environments.\n",
    "# Prepare the batch (vectorized) train function for <n_seeds> many runs\n",
    "jitted_batch_train = jax.jit(\n",
    "    jax.vmap(\n",
    "        partial(\n",
    "            train.asynchronous,\n",
    "            learner_state=None,\n",
    "            value_star=jnp.full_like(init_value, jnp.nan),\n",
    "            behavior_policy_fn=lambda q, i: jaxdp.e_greedy_policy.q(q, **args[\"policy_fn\"]),\n",
    "            target_policy_fn=lambda q, i: jaxdp.greedy_policy.q(q),\n",
    "            update_fn=batch_update_fn,\n",
    "            sample_fn=lambda key, *_args: n_env_sampler(jrd.split(key, args[\"n_env\"]), *_args),\n",
    "            verbose=False,\n",
    "            **args[\"train_loop\"]\n",
    "        ), in_axes=(None, None, None, 0))\n",
    ")\n",
    "# Run the jitted and vectorized train function\n",
    "metrics, value, learner_state, sampler_state = jitted_batch_train(\n",
    "    n_env_sampler_state,\n",
    "    init_value,\n",
    "    mdp,\n",
    "    train_keys\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from plot_util import make_figure\n",
    "\n",
    "\n",
    "# Make dataframe from the metrics\n",
    "percentile = 25\n",
    "\n",
    "index = pd.MultiIndex.from_product(\n",
    "    [[\"gridworld\"], [\"q-learning\"],\n",
    "     list(range(0, args[\"train_loop\"][\"n_steps\"], args[\"train_loop\"][\"eval_period\"]))],\n",
    "    names=[\"ENV\", \"ALG\", \"STEP\"])\n",
    "columns = pd.MultiIndex.from_product(\n",
    "    [metrics._fields, [\"low\", \"med\", \"high\"]],\n",
    "    names=[\"METRIC\", \"PERCENTILE\"])\n",
    "\n",
    "data = []\n",
    "for name in metrics._fields:\n",
    "    values = getattr(metrics, name)\n",
    "    if values.ndim == 1:\n",
    "        values = values.reshape(1, -1)\n",
    "    percentiles = jnp.nanpercentile(\n",
    "        values, q=jnp.array([percentile, 50, 100 - percentile]), axis=0)\n",
    "    data.append(percentiles)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=jnp.stack(list(chain(*data)), axis=1), columns=columns, index=index)\n",
    "\n",
    "# Generate the figure\n",
    "make_figure(df.loc[\"gridworld\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
